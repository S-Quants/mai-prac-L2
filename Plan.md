## Friday

*Notes*: Thumbs up/Thumbs Down button in the Chat

0. **10 min of practicing with Ollama**
   - Running LLMs from local/Colab (Qwen2)
   - Ollama (refresh your Ollama)

1. **Understanding the Need for RAG**
   - Reducing hallucination
   - Bringing in enterprise data
   - Adding and removing data
   - Data access control
   - Adapting to new models as needed

2. **Making a Simple LLM Call and Building Data Loaders**

3. **Building the RAG Server with Langserve**
   - Use a basic frontend first
   - Upgrade the frontend

4. **Needs for Tools in LLMs**

5. **Adding Memory to LLM**

## Saturday

6. **Smarter Memory**
*Include KG*

7. **SQL + Vector DB**
   - Text to SQL (predictable)
   - *Install Postgres*
   - Search in LLMs
   - Table analysis (Colab and local)
   - Using CLIP and other HF models for multimodality

8. **RAG with Augmentation**

9. **LLM Theory**

## Sunday

10. **Evaluations and Governance**
    - Routing and guardrails in LLMs
    - Architecture
    - Agent workflows
    - Search Agents, Autogen Agents
    - [Summarize large documents](https://colab.research.google.com/drive/1c69CkJzFiT9TPGblqIO9ugndzd3nH-Ar?usp=sharing)

11. **Training LLM from Scratch**

12. **Finetuning**

13. **Finetuning Theory**

*Python 3.11* (Use Conda to downgrade from 3.12)
*Postgres 16*
*RAM*: 16GB (Intel-Windows) / MacBook Pro
*Disc*: 30GB
*Groq Cloud*

**Very comfortable with commandline** [Path setting etc...]
export PATH="/Library/PostgreSQL/16/bin/:$PATH"
